<!DOCTYPE HTML>
<!--
	Future Imperfect by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="single is-preload">

		<!-- Wrapper -->
			<div id="wrapper">
				<header id="header">
					<h1>
						<a href="index.html">Home</a> |
						<a href="research.html">Research</a> |
						<a href="projects.html">Projects</a>
					</h1>
				</header>
				
				<article class="mini-post">
					<header>
						<div class="title">
							<h2>Research Experiences</h2>
						</div>
					</header>
				</article>
				
				<!-- Main -->
					<div id="main">

						<!-- Post: Multi-Agent Systems Research Group (small blurb) -->
							<article class="post">
								<div class="row aln-top gtr-uniform">
									<div class="col-3">
										<span class="image fit"><img src="assets/images/multi-agent.png" alt="Multi-Agent Systems Research Group" /></span>
									</div>
									<div class="col-9">
										<h2><a id="MAG"></a>Multi-Agent Systems Research Group</a></h2>
										<p>I'm a member of the University of Minnesota Multi-Agent Systems Research Group in the
											Next Generation Robotics Laboratory, where we study learning, cooperation, and adaptation
											in multi-agent robot systems.</p>
										<ul class="actions">
											<li><a href="https://nextgenai.umn.edu/multi-agent-group" target="_blank" class="button large">View Website</a></li>
										</ul>
									</div>
								</div>
							</article>

						<!-- Post: UT Austin -->
						<article class="post">
							<header>
								<div class="title">
									<h2><a id="UTAustin">Reinforcement Learning for Quadruped Locomotion</a></h2>
								</div>
								<div class="meta">
									<time class="published">06/2025 - 08/2025</time>
								</div>
							</header>
							<div class="row aln-top gtr-uniform">
								<div class="col-7">
									<span class="image fit"><img src="assets/images/go2.png" alt="Go2 picture" /></span>
								</div>
								<div class="col-5">
									<p><b>Reinforcement learning, simulation, and real robots</b><br>
									Researched reinforcement learning for quadruped locomotion with the Unitree Go2.
									Developed simulation environments and utilized reward design to achieve walking behavior.
									Built workflows connecting simulation with real-robot control for Sim-to-Real transfer.<br>
									Github for setting up an environment for communicating with a Go2 quadruped robot can be
									found <a href="https://github.com/gretab5802/go2-docker-env" target="_blank">here</a>.<br>
									Github for training walking behavior for a Go2 in MuJoCo simulation using Stablebaselines3
									PPO and SAC (and other policy gradient algorithms) can be found
									<a href="https://github.com/gretab5802/mujoco-go2-ppo" target="_blank">here</a>.</p>
								</div>
							</div>
						</article>

						<!-- Post: Farm Robotics Challenge (full block) -->
							<article class="post">
								<header>
									<div class="title">
										<h2><a id="FRC">Farm Robotics Challenge</a></h2>
									</div>
									<div class="meta">
										<time class="published">11/2024 - 04/2025</time>
									</div>
								</header>
								<div class="row aln-top gtr-uniform">
									<div class="col-7">
										<span class="image fit"><img src="assets/images/group_pic.jpg" alt="Group picture" /></span>
									</div>
									<div class="col-5">
										<p><b>Applied robotics in agriculture</b><br>
										Participated in the <a href="https://www.farmroboticschallenge.ai/" target="_blank">Farm Robotics Challenge</a>,
										to develop an award-winning system FarmGuard, which was designed to reduce deer intrusion in agricultural fields.
										Worked to combine hardware, computer vision, and path planning to effectively patrol and protect farmlands in
										collaboration with a local farmer.</p>
										<ul class="actions">
											<li><a href="https://ebasatemesgen.github.io/FarmGuard/" target="_blank" class="button large">View Website</a></li>
										</ul>
									</div>
								</div>
							</article>

						<!-- Post -->
							<article class="post">
								<header>
									<div class="title">
										<h2><a id="UROP">Undergraduate Research Opportunities Program (UROP)</a></h2>
									</div>
									<div class="meta">
										<time class="published">09/2024 - 12/2024</time>
									</div>
								</header>
								<div class="row aln-top gtr-uniform">
									<div class="col-7">
										<span class="image fit"><img src="assets/images/turtlebots.png" alt="TurtleBot3 robots used in UROP project" /></span>
									</div>
									<div class="col-5">
										<br><p><b>Fall Symposium Presentation</b><br>
										I presented this work at the University of Minnesota Undergraduate Research Symposium, highlighting the motivation,
										setup, and early platform results that enable future experiments in embodied evolution and reinforcement learning
										on physical TurtleBot3 robots. Additionally, you can read the abstract for this project below.</p>
										<ul class="actions">
											<li><a href="https://ugresearch.umn.edu/presentation-opportunities/fall-symposium/presenters/greta-brown" target="_blank" class="button large">View Presentation</a></li>
										</ul>
									</div>
								</div>
								<p><b>Social Learning and Behavioral Plasticity in Multi-Agent Robot Systems through Reinforcement Learning and Embodied Evolution</b> <br>
									A key objective in artificial intelligence and robotics is to develop systems capable of autonomous decision-making and adaptation
									to dynamic environments. Evolutionary robotics, a sub-field of robotics, aims to achieve this by drawing inspiration from natural
									evolution and applying principles of gene selection and variation within robots to enable adaptation. Embodied evolution, a subset
									of evolutionary robotics, distinguishes itself from other evolutionary algorithms by distributing control among the robots rather
									than centrally, allowing for asynchronous, autonomous, and continuous evolution. Reinforcement learning is a method for agents to
									learn autonomously based on trial-and-error learning. Researchers suggest that combining reinforcement learning with embodied evolution
									may enhance robotic collectives' adaptability in dynamic settings, an idea inspired by studies of behavioral plasticity and social
									learning in animal populations. This research takes an essential step toward testing these ideas in physical systems rather than
									simulations, which are commonly used but fail to address many real-world complexities. Using TurtleBot3 robots equipped with Raspberry
									Pi 4 and 5 modules, this work involved constructing the robots, equipping them with hardware, and setting up ROS 2 as a foundational
									environment for implementing reinforcement learning and embodied evolution. While the theoretical algorithms remain to be tested, this
									groundwork is crucial for transitioning these concepts from simulation to reality. The emphasis on physical deployment ensures that the
									challenges and nuances of real-world applications, often overlooked in simulation, are addressed, paving the way for adaptive robotic
									systems with greater practical utility.</p>
							</article>

					</div>

				<!-- Footer -->
					<section id="footer">
						<p class="copyright">&copy; Untitled. Design: <a href="http://html5up.net">HTML5 UP</a>. Images: <a href="http://unsplash.com">Unsplash</a>.</p>
					</section>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
